{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "execution_failed": "2025-10-26T07:48:42.742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, glob, time, json, math, random\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    def tqdm(x, **kwargs): return x\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "execution_failed": "2025-10-26T07:48:42.742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    data_dir: str = \"/kaggle/input/lgg-mri-segmentation/kaggle_3m\" \n",
    "    out_dir: str  = \"artifacts_lgg_en\"\n",
    "    run_name: str = \"lgg_multi_seg_en\"\n",
    "\n",
    "    img_size: Tuple[int,int] = (256, 256)\n",
    "    val_split: float = 0.10\n",
    "    test_split: float = 0.10\n",
    "    num_workers: int = 2\n",
    "    imagenet_norm: bool = True  \n",
    "\n",
    "    epochs: int = 40\n",
    "    warmup_epochs_frozen: int = 4  \n",
    "    batch_size: int = 8\n",
    "    lr: float = 3e-4\n",
    "    weight_decay: float = 1e-4\n",
    "    mixed_precision: bool = True\n",
    "\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    pin_memory: bool = True\n",
    "\n",
    "cfg = Config()\n",
    "os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "seed_everything(cfg.seed)\n",
    "print(\"Device:\", cfg.device)\n",
    "print(\"Output dir:\", cfg.out_dir)\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "execution_failed": "2025-10-26T07:48:42.742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IMG_EXTS = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\")\n",
    "\n",
    "def is_image(p: str) -> bool:\n",
    "    return os.path.splitext(p)[1].lower() in IMG_EXTS\n",
    "\n",
    "def _patient_id_from(dirpath: str, root: str) -> str:\n",
    "    rel = os.path.relpath(dirpath, root)\n",
    "    parts = [p for p in rel.split(os.sep) if p not in (\".\", \"\")]\n",
    "    return parts[0] if parts else os.path.basename(dirpath)\n",
    "\n",
    "def _normalize_stem(basename: str) -> str:\n",
    "    stem = os.path.splitext(basename)[0].lower()\n",
    "    tokens = [\n",
    "        \"_mask\", \"-mask\", \" mask\",\n",
    "        \"_seg\", \"-seg\", \" seg\",\n",
    "        \"_segmentation\", \" segmentation\",\n",
    "        \"_gt\", \"-gt\", \" groundtruth\", \" ground_truth\",\n",
    "        \"_annotation\", \"-annotation\"\n",
    "    ]\n",
    "    for t in tokens:\n",
    "        stem = stem.replace(t, \"\")\n",
    "    stem = stem.replace(\"-\", \"_\").replace(\" \", \"\")\n",
    "    while \"__\" in stem:\n",
    "        stem = stem.replace(\"__\", \"_\")\n",
    "    return stem\n",
    "\n",
    "def list_lgg_pairs(root: str):\n",
    "    if not os.path.isdir(root):\n",
    "        raise FileNotFoundError(f\"Data root not found: {root}\")\n",
    "\n",
    "    images, masks = {}, {}\n",
    "    for dirpath, _, files in os.walk(root):\n",
    "        rel_parts = os.path.relpath(dirpath, root).split(os.sep)\n",
    "        in_mask_dir = any(p.lower() in (\"mask\", \"masks\") for p in rel_parts)\n",
    "        for f in files:\n",
    "            if not is_image(f): continue\n",
    "            full = os.path.join(dirpath, f)\n",
    "            pid = _patient_id_from(dirpath, root)\n",
    "            base = os.path.basename(f)\n",
    "            is_mask_file = (\"mask\" in base.lower()) or (\"seg\" in base.lower()) or (\"gt\" in base.lower()) or (\"annot\" in base.lower()) or in_mask_dir\n",
    "            key = (pid, _normalize_stem(base))\n",
    "            if is_mask_file:\n",
    "                masks.setdefault(key, []).append(full)\n",
    "            else:\n",
    "                images.setdefault(key, []).append(full)\n",
    "\n",
    "    pairs = []\n",
    "    for key in sorted(set(images.keys()) & set(masks.keys())):\n",
    "        pairs.append((images[key][0], masks[key][0], key[0])) \n",
    "\n",
    "    if not pairs:\n",
    "        candidates = []\n",
    "        for dirpath, _, files in os.walk(root):\n",
    "            for f in files:\n",
    "                if is_image(f) and (\"mask\" in f.lower() or \"seg\" in f.lower() or \"gt\" in f.lower() or \"annot\" in f.lower() or \"mask\" in dirpath.lower() or \"masks\" in dirpath.lower()):\n",
    "                    candidates.append(os.path.join(dirpath, f))\n",
    "        print(f\"[Diagnostics] Found {len(candidates)} mask-like files.\")\n",
    "        for p in candidates[:10]:\n",
    "            print(\"  -\", os.path.relpath(p, root))\n",
    "        raise RuntimeError(\"No (image, mask) pairs found. Review naming patterns or folder structure.\")\n",
    "\n",
    "    return pairs\n",
    "\n",
    "def split_by_patient(pairs, val_ratio: float, test_ratio: float, seed: int=42):\n",
    "    patients = sorted({pid for _,_,pid in pairs})\n",
    "    rng = random.Random(seed)\n",
    "    rng.shuffle(patients)\n",
    "    n = len(patients)\n",
    "    n_test = int(n * test_ratio)\n",
    "    n_val  = int(n * val_ratio)\n",
    "    n_train = n - n_val - n_test\n",
    "    train_p = set(patients[:n_train])\n",
    "    val_p   = set(patients[n_train:n_train+n_val])\n",
    "    test_p  = set(patients[n_train+n_val:])\n",
    "    tr = [p for p in pairs if p[2] in train_p]\n",
    "    va = [p for p in pairs if p[2] in val_p]\n",
    "    te = [p for p in pairs if p[2] in test_p]\n",
    "    return tr, va, te, patients\n",
    "\n",
    "class LGGSegmentationDataset(Dataset):\n",
    "    IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "    IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "    def __init__(self, pairs, img_size, augment=True, imagenet_norm=True):\n",
    "        self.pairs = pairs\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.imagenet_norm = imagenet_norm\n",
    "\n",
    "    def __len__(self): return len(self.pairs)\n",
    "\n",
    "    def _load(self, ip, mp):\n",
    "        img = Image.open(ip).convert(\"RGB\")\n",
    "        msk = Image.open(mp).convert(\"L\")\n",
    "        return img, msk\n",
    "\n",
    "    def _resize(self, img, msk):\n",
    "        H,W = self.img_size\n",
    "        img = TF.resize(img, size=[H,W], interpolation=TF.InterpolationMode.BILINEAR)\n",
    "        msk = TF.resize(msk, size=[H,W], interpolation=TF.InterpolationMode.NEAREST)\n",
    "        return img, msk\n",
    "\n",
    "    def _augment(self, img, msk):\n",
    "        if random.random() < 0.5:\n",
    "            img = TF.hflip(img); msk = TF.hflip(msk)\n",
    "        angle = random.uniform(-20, 20)\n",
    "        translate = (int(random.uniform(-0.05,0.05)*img.width),\n",
    "                     int(random.uniform(-0.05,0.05)*img.height))\n",
    "        scale = random.uniform(0.95, 1.05)\n",
    "        shear = random.uniform(-5, 5)\n",
    "        img = TF.affine(img, angle=angle, translate=translate, scale=scale, shear=[shear,0.0],\n",
    "                        interpolation=TF.InterpolationMode.BILINEAR)\n",
    "        msk = TF.affine(msk, angle=angle, translate=translate, scale=scale, shear=[shear,0.0],\n",
    "                        interpolation=TF.InterpolationMode.NEAREST)\n",
    "        return img, msk\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ip, mp, pid = self.pairs[idx]\n",
    "        img, msk = self._load(ip, mp)\n",
    "        img, msk = self._resize(img, msk)\n",
    "        if self.augment:\n",
    "            img, msk = self._augment(img, msk)\n",
    "        img_t = TF.to_tensor(img)  \n",
    "        if self.imagenet_norm:\n",
    "            img_t = TF.normalize(img_t, mean=self.IMAGENET_MEAN, std=self.IMAGENET_STD)\n",
    "        msk_t = torch.from_numpy(np.array(msk, dtype=np.uint8))\n",
    "        msk_t = (msk_t > 127).float().unsqueeze(0) \n",
    "        return img_t, msk_t, ip, mp, pid\n",
    "\n",
    "def make_dataloaders(cfg):\n",
    "    pairs = list_lgg_pairs(cfg.data_dir)\n",
    "    tr, va, te, patients = split_by_patient(pairs, cfg.val_split, cfg.test_split, cfg.seed)\n",
    "    print(f\"Patients: {len(patients)}\")\n",
    "    print(f\"Pairs: train={len(tr)} | val={len(va)} | test={len(te)}\")\n",
    "\n",
    "    pin = cfg.pin_memory and (cfg.device == \"cuda\")\n",
    "    train_ds = LGGSegmentationDataset(tr, cfg.img_size, augment=True,  imagenet_norm=cfg.imagenet_norm)\n",
    "    val_ds   = LGGSegmentationDataset(va, cfg.img_size, augment=False, imagenet_norm=cfg.imagenet_norm)\n",
    "    test_ds  = LGGSegmentationDataset(te, cfg.img_size, augment=False, imagenet_norm=cfg.imagenet_norm)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True,  num_workers=cfg.num_workers, pin_memory=pin, drop_last=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers, pin_memory=pin)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers, pin_memory=pin)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-10-25T14:19:15.358398Z",
     "iopub.status.busy": "2025-10-25T14:19:15.358203Z",
     "iopub.status.idle": "2025-10-25T14:19:15.373748Z",
     "shell.execute_reply": "2025-10-25T14:19:15.373078Z",
     "shell.execute_reply.started": "2025-10-25T14:19:15.358383Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Run once after setting cfg.data_dir to verify pairing:\n",
    "# pairs = list_lgg_pairs(cfg.data_dir)\n",
    "# print(\"Total pairs:\", len(pairs))\n",
    "# for i, (ip, mp, pid) in enumerate(pairs[:5]):\n",
    "#     print(f\"{i+1:02d} [patient={pid}]\")\n",
    "#     print(\"  image:\", os.path.relpath(ip, cfg.data_dir))\n",
    "#     print(\"  mask :\", os.path.relpath(mp, cfg.data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-10-25T14:19:15.374855Z",
     "iopub.status.busy": "2025-10-25T14:19:15.374628Z",
     "iopub.status.idle": "2025-10-25T14:19:15.393001Z",
     "shell.execute_reply": "2025-10-25T14:19:15.392353Z",
     "shell.execute_reply.started": "2025-10-25T14:19:15.374835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "def build_deeplabv3_resnet50():\n",
    "    try:\n",
    "        w = models.segmentation.DeepLabV3_ResNet50_Weights.DEFAULT\n",
    "        m = models.segmentation.deeplabv3_resnet50(weights=w)\n",
    "    except Exception:\n",
    "        m = models.segmentation.deeplabv3_resnet50(weights=None)\n",
    "    in_ch = m.classifier[-1].in_channels if hasattr(m.classifier[-1], \"in_channels\") else 256\n",
    "    m.classifier[-1] = nn.Conv2d(in_ch, 1, kernel_size=1)\n",
    "    if hasattr(m, \"aux_classifier\") and m.aux_classifier is not None:\n",
    "        in_ch_aux = m.aux_classifier[-1].in_channels if hasattr(m.aux_classifier[-1], \"in_channels\") else 256\n",
    "        m.aux_classifier[-1] = nn.Conv2d(in_ch_aux, 1, kernel_size=1)\n",
    "    return m\n",
    "\n",
    "def build_deeplabv3_resnet101():\n",
    "    try:\n",
    "        w = models.segmentation.DeepLabV3_ResNet101_Weights.DEFAULT\n",
    "        m = models.segmentation.deeplabv3_resnet101(weights=w)\n",
    "    except Exception:\n",
    "        m = models.segmentation.deeplab3_resnet101(weights=None)\n",
    "    in_ch = m.classifier[-1].in_channels if hasattr(m.classifier[-1], \"in_channels\") else 256\n",
    "    m.classifier[-1] = nn.Conv2d(in_ch, 1, kernel_size=1)\n",
    "    if hasattr(m, \"aux_classifier\") and m.aux_classifier is not None:\n",
    "        in_ch_aux = m.aux_classifier[-1].in_channels if hasattr(m.aux_classifier[-1], \"in_channels\") else 256\n",
    "        m.aux_classifier[-1] = nn.Conv2d(in_ch_aux, 1, kernel_size=1)\n",
    "    return m\n",
    "\n",
    "def build_fcn_resnet50():\n",
    "    try:\n",
    "        w = models.segmentation.FCN_ResNet50_Weights.DEFAULT\n",
    "        m = models.segmentation.fcn_resnet50(weights=w)\n",
    "    except Exception:\n",
    "        m = models.segmentation.fcn_resnet50(weights=None)\n",
    "    in_ch = m.classifier[-1].in_channels if hasattr(m.classifier[-1], \"in_channels\") else 512\n",
    "    m.classifier[-1] = nn.Conv2d(in_ch, 1, kernel_size=1)\n",
    "    if hasattr(m, \"aux_classifier\") and m.aux_classifier is not None:\n",
    "        in_ch_aux = m.aux_classifier[-1].in_channels if hasattr(m.aux_classifier[-1], \"in_channels\") else 256\n",
    "        m.aux_classifier[-1] = nn.Conv2d(in_ch_aux, 1, kernel_size=1)\n",
    "    return m\n",
    "\n",
    "def build_lraspp_mobilenet_v3():\n",
    "    try:\n",
    "        w = models.segmentation.LRASPP_MobileNet_V3_Large_Weights.DEFAULT\n",
    "        m = models.segmentation.lraspp_mobilenet_v3_large(weights=w)\n",
    "    except Exception:\n",
    "        m = models.segmentation.lraspp_mobilenet_v3_large(weights=None)\n",
    "    # Adjust final classifier to 1 channel\n",
    "    m.classifier.high_classifier[4] = nn.Conv2d(128, 1, kernel_size=1)\n",
    "    return m\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "        self.proj = nn.Identity() if in_ch==out_ch else nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "    def forward(self, x):\n",
    "        idt = self.proj(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = F.relu(x + idt, inplace=True)\n",
    "        return x\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = ResBlock(in_ch, out_ch)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "    def forward(self, x):\n",
    "        x = self.block(x); return x, self.pool(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_ch, out_ch, 2, 2)\n",
    "        self.block = ResBlock(in_ch, out_ch)\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        if x.shape[-1]!=skip.shape[-1] or x.shape[-2]!=skip.shape[-2]:\n",
    "            dx = skip.shape[-1]-x.shape[-1]; dy = skip.shape[-2]-x.shape[-2]\n",
    "            x = F.pad(x, [dx//2, dx-dx//2, dy//2, dy-dy//2])\n",
    "        x = torch.cat([skip, x], dim=1)\n",
    "        return self.block(x)\n",
    "\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, base=64):\n",
    "        super().__init__()\n",
    "        self.in_conv = ResBlock(3, base)\n",
    "        self.d1 = Down(base, base*2)\n",
    "        self.d2 = Down(base*2, base*4)\n",
    "        self.d3 = Down(base*4, base*8)\n",
    "        self.bot = ResBlock(base*8, base*16)\n",
    "        self.u3 = Up(base*16, base*8)\n",
    "        self.u2 = Up(base*8, base*4)\n",
    "        self.u1 = Up(base*4, base*2)\n",
    "        self.u0 = Up(base*2, base)\n",
    "        self.out = nn.Conv2d(base, 1, 1)\n",
    "    def forward(self, x):\n",
    "        x0 = self.in_conv(x)\n",
    "        x1, p1 = self.d1(x0)\n",
    "        x2, p2 = self.d2(p1)\n",
    "        x3, p3 = self.d3(p2)\n",
    "        xb = self.bot(p3)\n",
    "        x = self.u3(xb, x3)\n",
    "        x = self.u2(x, x2)\n",
    "        x = self.u1(x, x1)\n",
    "        x = self.u0(x, x0)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-10-25T14:19:15.393876Z",
     "iopub.status.busy": "2025-10-25T14:19:15.393638Z",
     "iopub.status.idle": "2025-10-25T14:19:15.412411Z",
     "shell.execute_reply": "2025-10-25T14:19:15.411735Z",
     "shell.execute_reply.started": "2025-10-25T14:19:15.393854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth: float=1.0):\n",
    "        super().__init__(); self.smooth=smooth\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        num = 2.0*(probs*targets).sum(dim=(2,3)) + self.smooth\n",
    "        den = (probs + targets).sum(dim=(2,3)) + self.smooth\n",
    "        dice = (num/den).mean()\n",
    "        return 1.0 - dice\n",
    "\n",
    "def bce_dice_loss(logits, targets):\n",
    "    return F.binary_cross_entropy_with_logits(logits, targets) + DiceLoss()(logits, targets)\n",
    "\n",
    "@torch.no_grad()\n",
    "def seg_counts(logits, targets, thr: float=0.5):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    pred = (probs > thr).to(targets.dtype)\n",
    "    y = targets.to(targets.dtype)\n",
    "    tp = (pred*y).sum().item()\n",
    "    fp = (pred*(1-y)).sum().item()\n",
    "    fn = ((1-pred)*y).sum().item()\n",
    "    tn = ((1-pred)*(1-y)).sum().item()\n",
    "    total = y.numel()\n",
    "    return tp, fp, fn, tn, total\n",
    "\n",
    "@torch.no_grad()\n",
    "def seg_metrics(tp, fp, fn, tn, total) -> Dict[str,float]:\n",
    "    eps = 1e-12\n",
    "    acc = (tp+tn)/(total+eps)\n",
    "    prec = tp/(tp+fp+eps)\n",
    "    rec = tp/(tp+fn+eps)\n",
    "    f1 = 2*prec*rec/(prec+rec+eps)\n",
    "    iou = tp/(tp+fp+fn+eps)\n",
    "    dice = 2*tp/(2*tp+fp+fn+eps)\n",
    "    return {\"accuracy\":float(acc), \"precision\":float(prec), \"recall\":float(rec), \"f1\":float(f1), \"iou\":float(iou), \"dice\":float(dice)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-10-25T14:19:15.413357Z",
     "iopub.status.busy": "2025-10-25T14:19:15.413152Z",
     "iopub.status.idle": "2025-10-25T14:19:15.434601Z",
     "shell.execute_reply": "2025-10-25T14:19:15.433955Z",
     "shell.execute_reply.started": "2025-10-25T14:19:15.413335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def freeze_backbone(model):\n",
    "    for n,p in model.named_parameters():\n",
    "        if any(k in n for k in [\"classifier\", \"aux_classifier\"]):\n",
    "            p.requires_grad=True\n",
    "        else:\n",
    "            p.requires_grad=False\n",
    "\n",
    "def unfreeze_all(model):\n",
    "    for p in model.parameters(): p.requires_grad=True\n",
    "\n",
    "def forward_logits(model, x):\n",
    "    out = model(x)\n",
    "    if isinstance(out, dict) and \"out\" in out: return out[\"out\"]\n",
    "    return out\n",
    "\n",
    "def train_eval_model(model, loaders, cfg, tag: str):\n",
    "    train_loader, val_loader, test_loader = loaders\n",
    "    device = cfg.device\n",
    "    model.to(device)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(cfg.mixed_precision and (device=='cuda')))\n",
    "\n",
    "    freeze_backbone(model)\n",
    "    head_opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    head_sch = torch.optim.lr_scheduler.ReduceLROnPlateau(head_opt, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    hist = {\"epoch\": [], \"train_loss\": [], \"val_loss\": [], \"val_dice\": []}\n",
    "    best_dice = -1.0\n",
    "    best_path = os.path.join(cfg.out_dir, f\"{cfg.run_name}_{tag}_best.pt\")\n",
    "\n",
    "    def run_epoch(loader, train: bool):\n",
    "        if train: model.train()\n",
    "        else: model.eval()\n",
    "        total_loss = 0.0\n",
    "        tp=fp=fn=tn=total=0\n",
    "        for imgs, msks, *_ in tqdm(loader, desc=\"Train\" if train else \"Eval\", leave=False):\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            msks = msks.to(device, non_blocking=True)\n",
    "            with torch.cuda.amp.autocast(enabled=(cfg.mixed_precision and (device=='cuda'))):\n",
    "                logits = forward_logits(model, imgs)\n",
    "                if logits.shape[1] != 1: logits = logits[:, :1, ...]\n",
    "                loss = bce_dice_loss(logits, msks)\n",
    "            if train:\n",
    "                head_opt.zero_grad(set_to_none=True)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(head_opt)\n",
    "                scaler.update()\n",
    "            total_loss += loss.item()\n",
    "            a,b,c,d,t = seg_counts(logits, msks)\n",
    "            tp+=a; fp+=b; fn+=c; tn+=d; total+=t\n",
    "        return total_loss/len(loader), seg_metrics(tp,fp,fn,tn,total)\n",
    "\n",
    "    for epoch in range(1, cfg.warmup_epochs_frozen+1):\n",
    "        tr_loss, _ = run_epoch(train_loader, True)\n",
    "        va_loss, va_m = run_epoch(val_loader, False)\n",
    "        head_sch.step(va_loss)\n",
    "        hist[\"epoch\"].append(epoch)\n",
    "        hist[\"train_loss\"].append(tr_loss)\n",
    "        hist[\"val_loss\"].append(va_loss)\n",
    "        hist[\"val_dice\"].append(va_m[\"dice\"])\n",
    "        print(f\"[{tag}] Warmup {epoch}/{cfg.warmup_epochs_frozen} | train={tr_loss:.4f} | val={va_loss:.4f} | Dice={va_m['dice']:.4f}\")\n",
    "        if va_m[\"dice\"] > best_dice:\n",
    "            best_dice = va_m[\"dice\"]\n",
    "            torch.save({\"model_state\": model.state_dict(), \"val_metrics\": va_m, \"cfg\": asdict(cfg)}, best_path)\n",
    "            print(f\"  ✓ Saved best (Dice={best_dice:.4f}) → {best_path}\")\n",
    "\n",
    "    unfreeze_all(model)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    for epoch in range(cfg.warmup_epochs_frozen+1, cfg.epochs+1):\n",
    "        tr_loss, _ = run_epoch(train_loader, True)\n",
    "        va_loss, va_m = run_epoch(val_loader, False)\n",
    "        sch.step(va_loss)\n",
    "        hist[\"epoch\"].append(epoch)\n",
    "        hist[\"train_loss\"].append(tr_loss)\n",
    "        hist[\"val_loss\"].append(va_loss)\n",
    "        hist[\"val_dice\"].append(va_m[\"dice\"])\n",
    "        print(f\"[{tag}] Epoch {epoch}/{cfg.epochs} | train={tr_loss:.4f} | val={va_loss:.4f} \"\n",
    "              f\"| Acc={va_m['accuracy']:.4f} P/R/F1={va_m['precision']:.4f}/{va_m['recall']:.4f}/{va_m['f1']:.4f} \"\n",
    "              f\"| IoU={va_m['iou']:.4f} | Dice={va_m['dice']:.4f}\")\n",
    "        if va_m['dice'] > best_dice:\n",
    "            best_dice = va_m['dice']\n",
    "            torch.save({\"model_state\": model.state_dict(), \"val_metrics\": va_m, \"cfg\": asdict(cfg)}, best_path)\n",
    "            print(f\"  ✓ Saved best (Dice={best_dice:.4f}) → {best_path}\")\n",
    "\n",
    "    # Curves\n",
    "    def plot_curve(xs, ys, title, xlabel, ylabel, savepath):\n",
    "        plt.figure(); plt.plot(xs, ys); plt.title(title); plt.xlabel(xlabel); plt.ylabel(ylabel); plt.grid(True)\n",
    "        plt.savefig(savepath, bbox_inches=\"tight\"); plt.show()\n",
    "    xs = hist[\"epoch\"]\n",
    "    plot_curve(xs, hist[\"train_loss\"], f\"{tag} — Train Loss\", \"Epoch\", \"Loss\", os.path.join(cfg.out_dir, f\"{cfg.run_name}_{tag}_train_loss.png\"))\n",
    "    plot_curve(xs, hist[\"val_loss\"],   f\"{tag} — Val Loss\",   \"Epoch\", \"Loss\", os.path.join(cfg.out_dir, f\"{cfg.run_name}_{tag}_val_loss.png\"))\n",
    "    plot_curve(xs, hist[\"val_dice\"],   f\"{tag} — Val Dice\",   \"Epoch\", \"Dice\", os.path.join(cfg.out_dir, f\"{cfg.run_name}_{tag}_val_dice.png\"))\n",
    "\n",
    "    # Test with best\n",
    "    ckpt = torch.load(best_path, map_location=cfg.device)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    model.eval()\n",
    "    tp=fp=fn=tn=total=0; test_loss=0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, msks, *_ in tqdm(test_loader, desc=\"Test\", leave=False):\n",
    "            imgs = imgs.to(device); msks = msks.to(device)\n",
    "            logits = forward_logits(model, imgs)\n",
    "            if logits.shape[1] != 1: logits = logits[:, :1, ...]\n",
    "            test_loss += bce_dice_loss(logits, msks).item()\n",
    "            a,b,c,d,t = seg_counts(logits, msks)\n",
    "            tp+=a; fp+=b; fn+=c; tn+=d; total+=t\n",
    "    test_loss /= len(test_loader)\n",
    "    test_m = seg_metrics(tp,fp,fn,tn,total)\n",
    "    return {\"tag\": tag, \"best_val_dice\": float(best_dice), \"test_loss\": float(test_loss), **test_m}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-10-25T14:19:15.435521Z",
     "iopub.status.busy": "2025-10-25T14:19:15.435308Z",
     "iopub.status.idle": "2025-10-25T14:19:15.454518Z",
     "shell.execute_reply": "2025-10-25T14:19:15.453969Z",
     "shell.execute_reply.started": "2025-10-25T14:19:15.435506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_all(cfg):\n",
    "    train_loader, val_loader, test_loader = make_dataloaders(cfg)\n",
    "    loaders = (train_loader, val_loader, test_loader)\n",
    "\n",
    "    builders = [\n",
    "        (\"deeplabv3_resnet50\",  build_deeplabv3_resnet50),\n",
    "        (\"deeplabv3_resnet101\", build_deeplabv3_resnet101),\n",
    "        (\"fcn_resnet50\",        build_fcn_resnet50),\n",
    "        (\"lraspp_mobilenetv3\",  build_lraspp_mobilenet_v3),\n",
    "        (\"resunet\",             lambda: ResUNet(base=64)),\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for tag, builder in builders:\n",
    "        print(f\"\\\\n=== Training {tag} ===\")\n",
    "        model = builder()\n",
    "        res = train_eval_model(model, loaders, cfg, tag)\n",
    "        results.append(res)\n",
    "\n",
    "    with open(os.path.join(cfg.out_dir, f\"{cfg.run_name}_summary.json\"), \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    best = max(results, key=lambda r: r[\"dice\"])\n",
    "\n",
    "    print(\"\\\\n==== Final Comparison (Test) ====\")\n",
    "    for r in results: print(r)\n",
    "    print(\"\\\\n==== Recommended Best Model (by Dice) ====\")\n",
    "    print(best)\n",
    "\n",
    "    labels = [r[\"tag\"] for r in results]\n",
    "    scores = [r[\"dice\"] for r in results]\n",
    "    plt.figure()\n",
    "    plt.bar(range(len(labels)), scores)\n",
    "    plt.xticks(range(len(labels)), labels, rotation=15)\n",
    "    plt.ylabel(\"Dice\")\n",
    "    plt.title(\"Model Comparison — Dice (Test)\")\n",
    "    plt.grid(True, axis=\"y\")\n",
    "    plt.savefig(os.path.join(cfg.out_dir, f\"{cfg.run_name}_dice_comparison.png\"), bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    return results, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-10-25T14:19:15.456014Z",
     "iopub.status.busy": "2025-10-25T14:19:15.455304Z",
     "iopub.status.idle": "2025-10-25T14:19:15.472779Z",
     "shell.execute_reply": "2025-10-25T14:19:15.472052Z",
     "shell.execute_reply.started": "2025-10-25T14:19:15.455998Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def show_predictions(model, loader, device, max_images: int=3, thr: float=0.5):\n",
    "    model.eval()\n",
    "    def logits_out(m, x):\n",
    "        out = m(x)\n",
    "        return out[\"out\"] if isinstance(out, dict) and \"out\" in out else out\n",
    "    shown = 0\n",
    "    for imgs, msks, ips, mps, pids in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        logits = logits_out(model, imgs)\n",
    "        if logits.shape[1] != 1: logits = logits[:, :1, ...]\n",
    "        probs = torch.sigmoid(logits).cpu()\n",
    "        preds = (probs > thr).float()\n",
    "        for i in range(imgs.size(0)):\n",
    "            if shown >= max_images: return\n",
    "            img = imgs[i].cpu().permute(1,2,0).numpy()\n",
    "            img = (img - img.min())/(img.max()-img.min()+1e-6)  \n",
    "            msk = msks[i].cpu().squeeze(0).numpy()\n",
    "            prd = preds[i].squeeze(0).numpy()\n",
    "            plt.figure(); plt.title(f\"Input — {os.path.basename(ips[i])}\"); plt.imshow(img); plt.axis(\"off\"); plt.show()\n",
    "            plt.figure(); plt.title(\"Ground Truth\"); plt.imshow(msk, cmap=\"gray\"); plt.axis(\"off\"); plt.show()\n",
    "            plt.figure(); plt.title(\"Prediction\"); plt.imshow(prd, cmap=\"gray\"); plt.axis(\"off\"); plt.show()\n",
    "            shown += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "execution_failed": "2025-10-26T07:48:42.738Z",
     "iopub.execute_input": "2025-10-25T14:19:15.474804Z",
     "iopub.status.busy": "2025-10-25T14:19:15.474613Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results, best = run_all(cfg)\n",
    "\n",
    "from pathlib import Path\n",
    "best_tag = best[\"tag\"]\n",
    "ckpt_path = Path(cfg.out_dir) / f\"{cfg.run_name}_{best_tag}_best.pt\"\n",
    "builder_map = {\n",
    "    \"deeplabv3_resnet50\": build_deeplabv3_resnet50,\n",
    "    \"deeplabv3_resnet101\": build_deeplabv3_resnet101,\n",
    "    \"fcn_resnet50\": build_fcn_resnet50,\n",
    "    \"lraspp_mobilenetv3\": build_lraspp_mobilenet_v3,\n",
    "    \"resunet\": lambda: ResUNet(base=64),\n",
    "}\n",
    "best_model = builder_map[best_tag]().to(cfg.device)\n",
    "ckpt = torch.load(ckpt_path, map_location=cfg.device)\n",
    "best_model.load_state_dict(ckpt[\"model_state\"])\n",
    "train_loader, val_loader, test_loader = make_dataloaders(cfg)\n",
    "show_predictions(best_model, test_loader, cfg.device, max_images=3)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
